#!/usr/bin/env python

# Run this before you deploy it on replicate
import os
import sys
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# append project directory to path so predict.py can be imported
sys.path.append('.')
from predict import MODEL_NAME, MODEL_CACHE

# Make cache folders
if not os.path.exists(MODEL_CACHE):
    os.makedirs(MODEL_CACHE)

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME, 
    torch_dtype=torch.float16, 
    device_map="cuda:0",
    trust_remote_code=True)

model.save_pretrained(MODEL_CACHE)